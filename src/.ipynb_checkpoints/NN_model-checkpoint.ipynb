{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns : ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "Shape: (284807, 31)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('../data/creditcard.csv')\n",
    "\n",
    "# Sanity check\n",
    "print ('Columns : {}\\nShape: {}'.format(list(dataset.columns), dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...         V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...   -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ...   -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...    0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ...   -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...   -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  Class  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the time columns since we dont need it\n",
    "dataset = dataset.drop(labels=['Time'], axis=1)\n",
    "\n",
    "# Let's see how the dataset looks now\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df):\n",
    "    '''This function takes in the data-frame and splits the data into test and train'''\n",
    "    \n",
    "    data_class1 = df.loc[df.Class == 1] \n",
    "    data_class0 = df.loc[df.Class == 0]\n",
    "    \n",
    "    l1 = int(data_class1.shape[0]*.8)\n",
    "    l0 = int(data_class0.shape[0]*.8)\n",
    "    \n",
    "    train = pd.concat([data_class1[:l1], data_class0[:l0]]); train = train.sample(frac=1)\n",
    "    test = pd.concat([data_class1[l1:], data_class0[l0:]]); test = test.sample(frac=1)\n",
    "    \n",
    "    y_train = train.Class; y_test = test.Class\n",
    "    X_train = train.drop(labels=['Class'],axis=1)\n",
    "    X_test = test.drop(labels=['Class'],axis=1)\n",
    "    \n",
    "    return (X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZES\n",
      "Training data: 227845\tTraining label: 227845\n",
      "Test data: 56962\tTest label: 56962\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(dataset)\n",
    "\n",
    "# Let's check the sizes\n",
    "print (\"SIZES\")\n",
    "print ('Training data: {}\\tTraining label: {}\\nTest data: {}\\tTest label: {}'\\\n",
    "      .format(X_train.shape[0], y_train.shape[0], X_test.shape[0], y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data\n",
      "Train: (227845, 29)\n",
      "Test: (56962, 29)\n"
     ]
    }
   ],
   "source": [
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "# Sanity check for shape\n",
    "print ('Shape of the data\\nTrain: {}\\nTest: {}'.format(X_train.shape,X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the necessary keras modules \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define the model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Stacking the layers\n",
    "model.add(Dense(56,input_dim=29, activation='relu'))\n",
    "model.add(Dense(56, activation='relu'))\n",
    "model.add(Dense(56, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 2s - loss: 0.0268 - acc: 0.9958\n",
      "Epoch 2/500\n",
      " - 2s - loss: 0.0032 - acc: 0.9994\n",
      "Epoch 3/500\n",
      " - 2s - loss: 0.0028 - acc: 0.9994\n",
      "Epoch 4/500\n",
      " - 2s - loss: 0.0026 - acc: 0.9994\n",
      "Epoch 5/500\n",
      " - 2s - loss: 0.0024 - acc: 0.9995\n",
      "Epoch 6/500\n",
      " - 2s - loss: 0.0023 - acc: 0.9995\n",
      "Epoch 7/500\n",
      " - 2s - loss: 0.0021 - acc: 0.9995\n",
      "Epoch 8/500\n",
      " - 2s - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 9/500\n",
      " - 2s - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 10/500\n",
      " - 2s - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 11/500\n",
      " - 2s - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 12/500\n",
      " - 2s - loss: 0.0014 - acc: 0.9996\n",
      "Epoch 13/500\n",
      " - 2s - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 14/500\n",
      " - 2s - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 15/500\n",
      " - 2s - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 16/500\n",
      " - 2s - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 17/500\n",
      " - 2s - loss: 8.9327e-04 - acc: 0.9997\n",
      "Epoch 18/500\n",
      " - 2s - loss: 7.9068e-04 - acc: 0.9998\n",
      "Epoch 19/500\n",
      " - 2s - loss: 8.6486e-04 - acc: 0.9998\n",
      "Epoch 20/500\n",
      " - 2s - loss: 7.5042e-04 - acc: 0.9998\n",
      "Epoch 21/500\n",
      " - 2s - loss: 7.5750e-04 - acc: 0.9998\n",
      "Epoch 22/500\n",
      " - 2s - loss: 6.8884e-04 - acc: 0.9998\n",
      "Epoch 23/500\n",
      " - 2s - loss: 7.1593e-04 - acc: 0.9998\n",
      "Epoch 24/500\n",
      " - 2s - loss: 6.9259e-04 - acc: 0.9998\n",
      "Epoch 25/500\n",
      " - 2s - loss: 5.2622e-04 - acc: 0.9999\n",
      "Epoch 26/500\n",
      " - 2s - loss: 5.2808e-04 - acc: 0.9998\n",
      "Epoch 27/500\n",
      " - 2s - loss: 8.2074e-04 - acc: 0.9998\n",
      "Epoch 28/500\n",
      " - 2s - loss: 6.1589e-04 - acc: 0.9998\n",
      "Epoch 29/500\n",
      " - 2s - loss: 4.3693e-04 - acc: 0.9999\n",
      "Epoch 30/500\n",
      " - 2s - loss: 4.6890e-04 - acc: 0.9999\n",
      "Epoch 31/500\n",
      " - 2s - loss: 3.9011e-04 - acc: 0.9999\n",
      "Epoch 32/500\n",
      " - 2s - loss: 6.2596e-04 - acc: 0.9998\n",
      "Epoch 33/500\n",
      " - 2s - loss: 5.1287e-04 - acc: 0.9998\n",
      "Epoch 34/500\n",
      " - 1s - loss: 4.1464e-04 - acc: 0.9999\n",
      "Epoch 35/500\n",
      " - 2s - loss: 4.5627e-04 - acc: 0.9999\n",
      "Epoch 36/500\n",
      " - 2s - loss: 4.5405e-04 - acc: 0.9999\n",
      "Epoch 37/500\n",
      " - 2s - loss: 4.5794e-04 - acc: 0.9999\n",
      "Epoch 38/500\n",
      " - 1s - loss: 3.7375e-04 - acc: 0.9999\n",
      "Epoch 39/500\n",
      " - 2s - loss: 5.8095e-04 - acc: 0.9998\n",
      "Epoch 40/500\n",
      " - 2s - loss: 4.6707e-04 - acc: 0.9999\n",
      "Epoch 41/500\n",
      " - 2s - loss: 3.3682e-04 - acc: 0.9999\n",
      "Epoch 42/500\n",
      " - 2s - loss: 3.8403e-04 - acc: 0.9999\n",
      "Epoch 43/500\n",
      " - 2s - loss: 4.9315e-04 - acc: 0.9999\n",
      "Epoch 44/500\n",
      " - 2s - loss: 3.8567e-04 - acc: 0.9999\n",
      "Epoch 45/500\n",
      " - 2s - loss: 3.1977e-04 - acc: 0.9999\n",
      "Epoch 46/500\n",
      " - 2s - loss: 3.1708e-04 - acc: 0.9999\n",
      "Epoch 47/500\n",
      " - 2s - loss: 5.8328e-04 - acc: 0.9998\n",
      "Epoch 48/500\n",
      " - 2s - loss: 5.1550e-04 - acc: 0.9998\n",
      "Epoch 49/500\n",
      " - 2s - loss: 4.4742e-04 - acc: 0.9999\n",
      "Epoch 50/500\n",
      " - 2s - loss: 2.6735e-04 - acc: 0.9999\n",
      "Epoch 51/500\n",
      " - 2s - loss: 3.5861e-04 - acc: 0.9999\n",
      "Epoch 52/500\n",
      " - 2s - loss: 3.4485e-04 - acc: 0.9999\n",
      "Epoch 53/500\n",
      " - 2s - loss: 2.8846e-04 - acc: 0.9999\n",
      "Epoch 54/500\n",
      " - 2s - loss: 3.3495e-04 - acc: 0.9999\n",
      "Epoch 55/500\n",
      " - 2s - loss: 5.8947e-04 - acc: 0.9998\n",
      "Epoch 56/500\n",
      " - 2s - loss: 4.7174e-04 - acc: 0.9999\n",
      "Epoch 57/500\n",
      " - 2s - loss: 3.4224e-04 - acc: 0.9999\n",
      "Epoch 58/500\n",
      " - 2s - loss: 3.1940e-04 - acc: 0.9999\n",
      "Epoch 59/500\n",
      " - 2s - loss: 3.0708e-04 - acc: 0.9999\n",
      "Epoch 60/500\n",
      " - 2s - loss: 3.2561e-04 - acc: 0.9999\n",
      "Epoch 61/500\n",
      " - 2s - loss: 4.5974e-04 - acc: 0.9999\n",
      "Epoch 62/500\n",
      " - 2s - loss: 3.0136e-04 - acc: 0.9999\n",
      "Epoch 63/500\n",
      " - 2s - loss: 3.8640e-04 - acc: 0.9999\n",
      "Epoch 64/500\n",
      " - 2s - loss: 4.3714e-04 - acc: 0.9999\n",
      "Epoch 65/500\n",
      " - 2s - loss: 3.0219e-04 - acc: 0.9999\n",
      "Epoch 66/500\n",
      " - 2s - loss: 3.3046e-04 - acc: 0.9999\n",
      "Epoch 67/500\n",
      " - 2s - loss: 4.9088e-04 - acc: 0.9999\n",
      "Epoch 68/500\n",
      " - 2s - loss: 2.7780e-04 - acc: 0.9999\n",
      "Epoch 69/500\n",
      " - 2s - loss: 2.3941e-04 - acc: 0.9999\n",
      "Epoch 70/500\n",
      " - 2s - loss: 2.7126e-04 - acc: 0.9999\n",
      "Epoch 71/500\n",
      " - 2s - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 72/500\n",
      " - 2s - loss: 4.0378e-04 - acc: 0.9999\n",
      "Epoch 73/500\n",
      " - 2s - loss: 3.9390e-04 - acc: 0.9999\n",
      "Epoch 74/500\n",
      " - 2s - loss: 4.5784e-04 - acc: 0.9999\n",
      "Epoch 75/500\n",
      " - 2s - loss: 2.4828e-04 - acc: 0.9999\n",
      "Epoch 76/500\n",
      " - 2s - loss: 2.0806e-04 - acc: 1.0000\n",
      "Epoch 77/500\n",
      " - 2s - loss: 3.2941e-04 - acc: 0.9999\n",
      "Epoch 78/500\n",
      " - 2s - loss: 3.3448e-04 - acc: 0.9999\n",
      "Epoch 79/500\n",
      " - 2s - loss: 2.8764e-04 - acc: 0.9999\n",
      "Epoch 80/500\n",
      " - 2s - loss: 3.7118e-04 - acc: 0.9999\n",
      "Epoch 81/500\n",
      " - 2s - loss: 2.9393e-04 - acc: 0.9999\n",
      "Epoch 82/500\n",
      " - 2s - loss: 3.1396e-04 - acc: 0.9999\n",
      "Epoch 83/500\n",
      " - 2s - loss: 4.9529e-04 - acc: 0.9998\n",
      "Epoch 84/500\n",
      " - 2s - loss: 4.0124e-04 - acc: 0.9999\n",
      "Epoch 85/500\n",
      " - 2s - loss: 2.9869e-04 - acc: 0.9999\n",
      "Epoch 86/500\n",
      " - 2s - loss: 2.3285e-04 - acc: 0.9999\n",
      "Epoch 87/500\n",
      " - 2s - loss: 2.1296e-04 - acc: 0.9999\n",
      "Epoch 88/500\n",
      " - 2s - loss: 2.2129e-04 - acc: 1.0000\n",
      "Epoch 89/500\n",
      " - 2s - loss: 3.1196e-04 - acc: 0.9999\n",
      "Epoch 90/500\n",
      " - 2s - loss: 4.7923e-04 - acc: 0.9999\n",
      "Epoch 91/500\n",
      " - 2s - loss: 3.5607e-04 - acc: 0.9999\n",
      "Epoch 92/500\n",
      " - 2s - loss: 2.6633e-04 - acc: 0.9999\n",
      "Epoch 93/500\n",
      " - 2s - loss: 1.8599e-04 - acc: 1.0000\n",
      "Epoch 94/500\n",
      " - 2s - loss: 1.7948e-04 - acc: 1.0000\n",
      "Epoch 95/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-7c6e1b7440c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1712\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=500, batch_size=512, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
